# positional-embeddings-comparison-study
Comparing positional embedding strategies (RoPE, PoPE, DroPE, NoPE, YaRN) for context length generalisation in transformers
